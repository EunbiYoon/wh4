Regularization parameter lambda=0.250

Initializing the network with the following structure (number of neurons per layer): [2 4 3 2]

Initial Theta1 (the weights of each neuron, including the bias weight, are stored in the rows):
	 0.42000   0.15000   0.40000  
	 0.72000   0.10000   0.54000  
	 0.01000   0.19000   0.42000  
	 0.30000   0.35000   0.68000  

Initial Theta2 (the weights of each neuron, including the bias weight, are stored in the rows):
	 0.21000   0.67000   0.14000   0.96000   0.87000  
	 0.87000   0.42000   0.20000   0.32000   0.89000  
	 0.03000   0.56000   0.80000   0.69000   0.09000  

Initial Theta3 (the weights of each neuron, including the bias weight, are stored in the rows):
	 0.04000   0.87000   0.42000   0.53000  
	 0.17000   0.10000   0.95000   0.69000  

Training set
	Training instance 1
		x: [0.32000   0.68000]
		y: [0.75000   0.98000]
	Training instance 2
		x: [0.83000   0.02000]
		y: [0.75000   0.28000]

--------------------------------------------
Computing the error/cost, J, of the network
	Processing training instance 1
	Forward propagating the input [0.32000   0.68000]
